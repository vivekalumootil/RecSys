{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e5c860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from https://medium.com/@jdwittenauer/deep-learning-with-keras-recommender-systems-e7b99cb29929\n",
    "# Relevant libraries: tensorflow, numpy, pandas\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model, model_from_json, load_model\n",
    "from keras.layers import Input, Reshape, Dot, Add, Activation, Lambda, Concatenate, Dense\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c5cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads past data\n",
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f10f4de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating  timestamp\n",
      "0            1     1193     5.0  978300760\n",
      "1            1      661     3.0  978302109\n",
      "2            1      914     3.0  978301968\n",
      "3            1     3408     4.0  978300275\n",
      "4            1     2355     5.0  978824291\n",
      "...        ...      ...     ...        ...\n",
      "999740    6038     1387     2.0  956707005\n",
      "999741    6038     2700     1.0  956715051\n",
      "999742    6038     2716     3.0  956707604\n",
      "999743    6038     3396     3.0  956706827\n",
      "999744    6038     1079     5.0  956707547\n",
      "\n",
      "[999745 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6039, 3952, 1, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets up some variables\n",
    "k = 1\n",
    "n_users = ratings['userId'].nunique() + k\n",
    "n_movies = ratings['movieId'].max()\n",
    "ratings['rating'] = ratings['rating'].values.astype(np.float32)\n",
    "min_rating = 1\n",
    "max_rating = 5\n",
    "print(ratings)\n",
    "\n",
    "n_users, n_movies, min_rating, max_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c6cb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up data\n",
    "X = np.array(ratings['userId'].values), np.array(ratings['movieId'].values)\n",
    "y = ratings['rating'].values\n",
    "n_factors = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52c0aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer class\n",
    "class EmbeddingLayer:\n",
    "    def __init__(self, n_items, n_factors):\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = Embedding(self.n_items, self.n_factors, embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(x)\n",
    "        x = Reshape((self.n_factors,))(x)\n",
    "        return x\n",
    "\n",
    "# Graph of Neural Network\n",
    "# user --> u, u_1d\n",
    "# movie --> m, m_1d\n",
    "# sigmoid(u * m + u_1d + m_1d) --> output\n",
    "def NeuralNetwork(n_users, n_movies, n_factors, min_rating, max_rating):\n",
    "    user = Input(shape=(1,))\n",
    "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
    "    u_1d = EmbeddingLayer(n_users, 1)(user)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    m_1d = EmbeddingLayer(n_movies, 1)(movie)\n",
    "    \n",
    "    x = Dot(axes=1)([u, m])\n",
    "    x = Add()([x, u_1d, m_1d])\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    opt = adam_v2.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mae', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "872df71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_18 (Embedding)       (None, 1, 25)        151000      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_20 (Embedding)       (None, 1, 25)        98825       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_18 (Reshape)           (None, 25)           0           ['embedding_18[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_20 (Reshape)           (None, 25)           0           ['embedding_20[0][0]']           \n",
      "                                                                                                  \n",
      " embedding_19 (Embedding)       (None, 1, 1)         6040        ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_21 (Embedding)       (None, 1, 1)         3953        ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dot_12 (Dot)                   (None, 1)            0           ['reshape_18[0][0]',             \n",
      "                                                                  'reshape_20[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_19 (Reshape)           (None, 1)            0           ['embedding_19[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_21 (Reshape)           (None, 1)            0           ['embedding_21[0][0]']           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1)            0           ['dot_12[0][0]',                 \n",
      "                                                                  'reshape_19[0][0]',             \n",
      "                                                                  'reshape_21[0][0]']             \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1)            0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 259,818\n",
      "Trainable params: 259,818\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/4\n",
      " 6373/15622 [===========>..................] - ETA: 19s - loss: 0.84 - ETA: 19s - loss: 0.8488"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(n_users\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, n_movies\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, n_factors, min_rating, max_rating)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate model and fit to data\n",
    "model = NeuralNetwork(n_users+1, n_movies+1, n_factors, min_rating, max_rating)\n",
    "model.summary()\n",
    "history = model.fit(x=X, y=y, batch_size = 64,epochs=4,\n",
    "                    verbose=1)\n",
    "# model.evaluate(x=X, y=y, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d100d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15622/15622 [==============================] - 12s 757us/step - loss: 0.5941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5941396355628967"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model (on training set)\n",
    "model.evaluate(x=X, y=y, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "186cbbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivek/Library/Python/3.8/lib/python/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "# Save model to mf.h5\n",
    "f = 3\n",
    "tf.keras.models.save_model(model, 'mf' + str(f) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7f1c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a model\n",
    "g = 3\n",
    "upload_model = tf.keras.models.load_model('mf' + str(g) + '.h5', custom_objects={'EmbeddingLayer': EmbeddingLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c24a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15622/15622 [==============================] - 11s 695us/step - loss: 0.5941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5941396355628967"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded model (on training set)\n",
    "upload_model.evaluate(x=X, y=y, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adb5758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 116ms/step - loss: 0.5924 - val_loss: 0.6371\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5611 - val_loss: 0.6176\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5292 - val_loss: 0.5994\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4962 - val_loss: 0.5868\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.4719 - val_loss: 0.5791\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4597 - val_loss: 0.5743\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4522 - val_loss: 0.5725\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4440 - val_loss: 0.5711\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4323 - val_loss: 0.5711\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4188 - val_loss: 0.5711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151fd1c10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit test data\n",
    "# Website STEP 1\n",
    "\n",
    "# Given data about new user (used in training)\n",
    "# Do this for website \n",
    "new_ratings = pd.read_csv('new_user_ratings.csv')\n",
    "X_new = np.array(new_ratings['userId'].values), np.array(new_ratings['movieId'].values)\n",
    "y_new = new_ratings['rating'].values\n",
    "\n",
    "# Evaluative data about new user\n",
    "# Not relevant for website\n",
    "new_ratings_eval = pd.read_csv('new_user_test.csv')\n",
    "X_eval = np.array(new_ratings_eval['userId'].values), np.array(new_ratings_eval['movieId'].values)\n",
    "y_eval = new_ratings_eval['rating'].values\n",
    "\n",
    "# the number of epochs can be adjusted, 10 seems to work well\n",
    "# IMPORTANT, this fits the existing model with the data about user 6039\n",
    "upload_model.fit(x=X_new, y=y_new,epochs=10, validation_data = (X_eval, y_eval), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dbd05090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5715410113334656"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded model on non-training set\n",
    "# Not relevant for website\n",
    "new_ratings_eval = pd.read_csv('new_user_test.csv')\n",
    "X_eval = np.array(new_ratings_eval['userId'].values), np.array(new_ratings_eval['movieId'].values)\n",
    "y_eval = new_ratings_eval['rating'].values\n",
    "upload_model.evaluate(x=X_eval, y=y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b361d51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Code for making a specific prediction\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# This returns the prediction for user new_user and movie new_movie\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict([np\u001b[38;5;241m.\u001b[39marray([new_user]), np\u001b[38;5;241m.\u001b[39marray([new_movie])])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Code for making a specific prediction\n",
    "# This returns the prediction for user new_user and movie new_movie\n",
    "# Website STEP 2\n",
    "model.predict([np.array([new_user]), np.array([new_movie])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36660c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A brief guide:\n",
    "# The code in the second part of the program (mainly evaluation) is separate from the part of the program that trains the model\n",
    "# It is not necessary to train the model with the train data every single time (it can be uploaded from a file)\n",
    "# However, to upload from a file, you obviously need to download it at some point\n",
    "# To do this: run all of the code parts from the start up to model.fit part and then run the save model code\n",
    "# The train data consists of users 1-6038, the code tests user 6039\n",
    "# Here, I have included the partial ratings for 6039 that we could use to make recommendations for user 6039 in new_user_ratings\n",
    "# The last part of the code evaluates the model on the 6039 test in new_user_test\n",
    "# In your website, you would want to use the predict function and iterate over all movies and see which ones have the highest predicted ratings\n",
    "# In have labelled STEPS 1 and STEPS 2 which will hopefully help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46989fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
